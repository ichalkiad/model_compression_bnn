{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries imports\n",
    "import torch\n",
    "import edward\n",
    "from edward.models import Categorical\n",
    "import pandas as pd\n",
    "#from sklearn.metrics import mean_squared_error\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "#import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load test data and necessary data for prediction inspection\n",
    "\n",
    "with open('/tmp/PredictionPDF.pt','rb') as f:\n",
    "         probs = torch.load(f)\n",
    "#with open('/tmp/PDFCenters.pt','rb') as f:\n",
    "#         centers = torch.load(f)\n",
    "with open('../data/Wall/test_data_2sensors_1hot.pt','rb') as f:\n",
    "      test_ = torch.load(f)\n",
    "\n",
    "\n",
    "\n",
    "test_data = test_ \n",
    "N = len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inspect posterior predictive distribution\n",
    "\n",
    "y_post = []\n",
    "sigma_y = 1.0\n",
    "n_samples = 3000\n",
    "\n",
    "\n",
    "t0 = time.time()\n",
    "for i in xrange(N):\n",
    "    #print(\"Forming the posterior predictive distribution for test data point\", i+1, \"/\", len(test_data), \"...\")\n",
    "    y_post.append(Categorical(probs = probs[i]))\n",
    "    \n",
    "print(\"Took altogether\", np.int(time.time() - t0), \"secs.\")\n",
    "\n",
    "t0 = time.time()                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
    "print(\"Sampling the posterior predictive distribution for\", len(test_data), \"test data points...\")\n",
    "#posteriorsamplenodes = tf.stack([y_post[i].sample(n_samples) for i in range(N)], axis=1)\n",
    "#Posterior samples contain n_samples samples from each posterior predictive distribution, shape = n_samples x N\n",
    "psnodes = np.zeros((n_samples,N))\n",
    "with tf.Session().as_default():\n",
    "    for i in xrange(N):\n",
    "        psnodes[:,i] = y_post[i].sample(n_samples).eval()\n",
    "        \n",
    "    posteriorsamples = pd.DataFrame(psnodes)\n",
    "    \n",
    "#print(posteriorsamples)\n",
    "print(\"Took\", np.int(time.time() - t0), \"secs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inspect prediction statistics\n",
    "\n",
    "#Predictions are the mean over the #n_samples predicted values for each test data point\n",
    "predictions = posteriorsamples.mean()\n",
    "predictions_low = posteriorsamples.quantile(0.01)\n",
    "predictions_high = posteriorsamples.quantile(0.99)\n",
    "\n",
    "results = pd.DataFrame()\n",
    "results['Bayesian_prediction'] = predictions    \n",
    "results['Bayesian_prediction_low'] = predictions_low\n",
    "results['Bayesian_prediction_high'] = predictions_high\n",
    "\n",
    "#Results contain the accuracy of the predictions on the test data points\n",
    "print(\"Accuracy on test data for Bayesian neural network:\")\n",
    "print(len(np.where(results['Bayesian_prediction']==np.argmax(test_data[:,2:6],axis=1))[0])/float(len(test_data[:,2]))*100)\n",
    "#results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualise one (random) prediction and associated uncertainty\n",
    "\n",
    "test_sample_number = 1 #np.random.choice(range(len(test_data)))\n",
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "_, _, histogram = plt.hist(posteriorsamples[test_sample_number].values, bins=[0,1,2,3], density=True, align='left',rwidth=0.3)\n",
    "\n",
    "plt.xlabel(\"Predicted class\")\n",
    "plt.ylabel(\"PDF (counts/n_samples x binwidth)\")\n",
    "plt.axvline(results.loc[test_sample_number, 'Bayesian_prediction'], color='g', linewidth=4, label=\"Bayesian NN\")\n",
    "plt.axvline(test_data[test_sample_number,2], color='k', linewidth=4, label=\"Ground truth\")\n",
    "plt.legend()\n",
    "plt.title(\"Results for test data point \" + str(test_sample_number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
